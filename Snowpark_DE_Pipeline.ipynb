{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f1434da-f408-49c5-bac3-55efb10a4011",
   "metadata": {},
   "source": [
    "# Data Engineering -- Data Analysis and Data Preparation\r",
    "This Notebooe will focus on Data Engineering in Snowflake using Snowpark for Python.\r\n",
    "\r\n",
    "Load data from Snowflake tables into Snowpark DataFrames\r\n",
    "Perform Exploratory Data Analysis on Snowpark DataFrames\r\n",
    "Pivot and Join data from multiple tables using Snowpark DataFrames\r\n",
    "Demostrate how to automate data preparation using Snowflake Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba913f6-6e39-4509-8b56-9fd60d7c8ffd",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4fa0bec-9de5-4a3e-a1ea-d9046071ba6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Snowpark for Python\n",
    "from snowflake.snowpark.session import Session\n",
    "from snowflake.snowpark.functions import month,year,col,sum\n",
    "from snowflake.snowpark.version import VERSION\n",
    "from snowflake.core import Root\n",
    "from snowflake.core.task import Task, StoredProcedureCall\n",
    "from snowflake.core.task.dagv1 import DAG, DAGTask, DAGOperation\n",
    "from snowflake.core import CreateMode\n",
    "\n",
    "# Misc\n",
    "from datetime import timedelta\n",
    "import json\n",
    "import logging \n",
    "logger = logging.getLogger(\"snowflake.snowpark.session\")\n",
    "logger.setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6a14b7-8246-4298-8dc0-806d309f5637",
   "metadata": {},
   "source": [
    "# Establish Secure Connection to Snowflake\r\n",
    "Using the Snowpark Python API, itâ€™s quick and easy to establish a secure connection between Snowflake and Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b5754bf-e665-4adf-af60-6aa3cafddf68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User                        : SIDDHANT20\n",
      "Role                        : \"ACCOUNTADMIN\"\n",
      "Database                    : \"DASH_DB\"\n",
      "Schema                      : \"DASH_SCHEMA\"\n",
      "Warehouse                   : \"DASH_L\"\n",
      "Snowflake version           : 8.22.0\n",
      "Snowpark for Python version : 1.16.0\n"
     ]
    }
   ],
   "source": [
    "# Create Snowflake Session object\n",
    "connection_parameters = json.load(open('E:\\Projects\\Snowflake Project 2\\Config\\connection.json'))\n",
    "session = Session.builder.configs(connection_parameters).create()\n",
    "session.sql_simplifier_enabled = True\n",
    "\n",
    "snowflake_environment = session.sql('select current_user(), current_version()').collect()\n",
    "snowpark_version = VERSION\n",
    "\n",
    "# Current Environment Details\n",
    "print('User                        : {}'.format(snowflake_environment[0][0]))\n",
    "print('Role                        : {}'.format(session.get_current_role()))\n",
    "print('Database                    : {}'.format(session.get_current_database()))\n",
    "print('Schema                      : {}'.format(session.get_current_schema()))\n",
    "print('Warehouse                   : {}'.format(session.get_current_warehouse()))\n",
    "print('Snowflake version           : {}'.format(snowflake_environment[0][1]))\n",
    "print('Snowpark for Python version : {}.{}.{}'.format(snowpark_version[0],snowpark_version[1],snowpark_version[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc1a13d-8c04-4db1-b814-8d9c70ae9246",
   "metadata": {},
   "source": [
    "# Automation: Run Campaign Spend Data Transformations As a Snowflake Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "252dd477-810c-4d32-8af4-c85f5f97f32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def campaign_spend_data_pipeline(session: Session) -> str:\n",
    "  # DATA TRANSFORMATIONS\n",
    "  # Perform the following actions to transform the data\n",
    "\n",
    "  # Load the campaign spend data\n",
    "  snow_df_spend_t = session.table('campaign_spend')\n",
    "\n",
    "  # Transform the data so we can see total cost per year/month per channel using group_by() and agg() Snowpark DataFrame functions\n",
    "  snow_df_spend_per_channel_t = snow_df_spend_t.group_by(year('DATE'), month('DATE'),'CHANNEL').agg(sum('TOTAL_COST').as_('TOTAL_COST')).\\\n",
    "      with_column_renamed('\"YEAR(DATE)\"',\"YEAR\").with_column_renamed('\"MONTH(DATE)\"',\"MONTH\").sort('YEAR','MONTH')\n",
    "\n",
    "  # Transform the data so that each row will represent total cost across all channels per year/month using pivot() and sum() Snowpark DataFrame functions\n",
    "  snow_df_spend_per_month_t = snow_df_spend_per_channel_t.pivot('CHANNEL',['search_engine','social_media','video','email']).sum('TOTAL_COST').sort('YEAR','MONTH')\n",
    "  snow_df_spend_per_month_t = snow_df_spend_per_month_t.select(\n",
    "      col(\"YEAR\"),\n",
    "      col(\"MONTH\"),\n",
    "      col(\"'search_engine'\").as_(\"SEARCH_ENGINE\"),\n",
    "      col(\"'social_media'\").as_(\"SOCIAL_MEDIA\"),\n",
    "      col(\"'video'\").as_(\"VIDEO\"),\n",
    "      col(\"'email'\").as_(\"EMAIL\")\n",
    "  )\n",
    "\n",
    "  # Save transformed data\n",
    "  snow_df_spend_per_month_t.write.mode('overwrite').save_as_table('SPEND_PER_MONTH')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df4103ae-2766-4659-ab9d-fad6f3f58050",
   "metadata": {},
   "source": [
    "# Automation: Run Monthly Revenue Data Transformations As a Snowflake Task "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "93bb649a-b49d-4c49-ad91-c42f302eaab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def monthly_revenue_data_pipeline(session: Session) -> str:\n",
    "  # Load revenue table and transform the data into revenue per year/month using group_by and agg() functions\n",
    "  snow_df_spend_per_month_t = session.table('spend_per_month')\n",
    "  snow_df_revenue_t = session.table('monthly_revenue')\n",
    "  snow_df_revenue_per_month_t = snow_df_revenue_t.group_by('YEAR','MONTH').agg(sum('REVENUE')).sort('YEAR','MONTH').with_column_renamed('SUM(REVENUE)','REVENUE')\n",
    "\n",
    "  # Join revenue data with the transformed campaign spend data so that our input features (i.e. cost per channel) and target variable (i.e. revenue) can be loaded into a single table for model training\n",
    "  snow_df_spend_and_revenue_per_month_t = snow_df_spend_per_month_t.join(snow_df_revenue_per_month_t, [\"YEAR\",\"MONTH\"])\n",
    "\n",
    "  # SAVE in a new table for the next task\n",
    "  snow_df_spend_and_revenue_per_month_t.write.mode('overwrite').save_as_table('SPEND_AND_REVENUE_PER_MONTH')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d516f8-1030-4e75-9b28-8abba66e6d99",
   "metadata": {},
   "source": [
    "# Create DAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "03d4d01a-c5e3-46f1-83bc-378a0a48e8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = Root(session)\n",
    "tasks = root.databases[session.get_current_database()].schemas[session.get_current_schema()].tasks\n",
    "\n",
    "with DAG(\"de_pipeline_dag\", schedule=timedelta(minutes=3)) as dag:\n",
    "    # Create a task that runs our first pipleine\n",
    "    dag_spend_task = DAGTask(name='campaign_spend_data_pipeline_task'\n",
    "                        , definition=StoredProcedureCall(\n",
    "                                    campaign_spend_data_pipeline, stage_location='@dash_sprocs'\n",
    "                                )\n",
    "                        ,warehouse='DASH_L'\n",
    "                        )\n",
    "    # Create a task that runs our second pipleine\n",
    "    dag_revenue_task = DAGTask(name='monthly_revenue_data_pipeline'\n",
    "                          , definition=StoredProcedureCall(\n",
    "                                monthly_revenue_data_pipeline, stage_location='@dash_sprocs'\n",
    "                            )\n",
    "                        ,warehouse='DASH_L'\n",
    "                        )\n",
    "# Shift right and left operators can specify task relationships.\n",
    "dag_spend_task >> dag_revenue_task  # dag_spend_task is a predecessor of dag_revenue_task\n",
    "\n",
    "schema = root.databases[session.get_current_database()].schemas[session.get_current_schema()]\n",
    "dag_op = DAGOperation(schema)\n",
    "\n",
    "dag_op.deploy(dag,mode=CreateMode.or_replace)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a298fe-6ea3-4b9a-b47f-d03a18a85bd1",
   "metadata": {},
   "source": [
    "# Run DAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "15162bea-c071-4fe1-8b1e-3b44b53eca84",
   "metadata": {},
   "outputs": [],
   "source": [
    "dag_op.run(dag)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad4ee4b-869a-47f4-8b00-f40a568bc808",
   "metadata": {},
   "source": [
    "# Resume DAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "09e55b45-75c2-46f3-99ca-d3eba697c250",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_task = tasks[\"DE_PIPELINE_DAG\"]\n",
    "root_task.resume()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d7791c-0cd5-4666-bd42-86dc76727b3b",
   "metadata": {},
   "source": [
    "# Suspend Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f403d603-2d8e-4ded-84fc-765310e6fb07",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_task = tasks[\"DE_PIPELINE_DAG\"]\n",
    "root_task.suspend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
